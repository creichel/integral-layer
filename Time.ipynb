{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.setdefaulttensortype('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load `Integral` and test it right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output mean relative error:\t1.3956582564299e-06 %\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "gradInput mean relative error:\t6.0973558033049e-07 %\t\n",
       "gradParams mean relative error:\t2.8068720841962e-05 %\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'image'\n",
    "local lena = image.lena():mean(1):squeeze()[{{1,4}, {1,4}}]\n",
    "\n",
    "Integral = nil\n",
    "debug.getregistry()['Integral'] = nil \n",
    "package.loaded['Integral-c'] = nil\n",
    "package.loaded['Integral-c-multi'] = nil\n",
    "package.loaded['Integral-jit'] = nil\n",
    "package.loaded['Integral-jit-multi'] = nil\n",
    "package.loaded['Integral-cuda-multi'] = nil\n",
    "require 'Integral-jit-multi'\n",
    "\n",
    "-- compute true forward and backward results for some data\n",
    "local intGold = Integral(16, 4, 4)\n",
    "local params, gradParamsGold = intGold:getParameters()\n",
    "\n",
    "local forwardGold = intGold:forward(lena)\n",
    "local gradInputGold = intGold:backward(lena, forwardGold)\n",
    "\n",
    "-- remove the old slow class\n",
    "Integral = nil\n",
    "debug.getregistry()['Integral'] = nil \n",
    "package.loaded['Integral-c'] = nil\n",
    "package.loaded['Integral-c-multi'] = nil\n",
    "package.loaded['Integral-jit'] = nil\n",
    "package.loaded['Integral-jit-multi'] = nil\n",
    "package.loaded['Integral-cuda-multi'] = nil\n",
    "\n",
    "-- require the new fast class\n",
    "require 'Integral-cuda-multi'\n",
    "\n",
    "local intTest = Integral(16, 4, 4):cuda()\n",
    "local paramsTest, gradParamsTest = intTest:getParameters()\n",
    "\n",
    "paramsTest:copy(params)\n",
    "intTest:recalculateArea()\n",
    "\n",
    "lena = lena:type(intTest:type())\n",
    "\n",
    "-- compare results\n",
    "local forwardTest = intTest:forward(lena)\n",
    "local forwardErr = (forwardGold - forwardTest:float()):abs():sum() / \n",
    "                   forwardTest:nElement() / torch.abs(forwardGold):mean()\n",
    "print('Output mean relative error:', forwardErr * 100 .. ' %')\n",
    "\n",
    "local gradInputTest = intTest:backward(lena, forwardGold:type(intTest:type()))\n",
    "local gradInputErr = (gradInputGold - gradInputTest:float()):abs():sum() / \n",
    "                     gradInputTest:nElement() / torch.abs(gradInputGold):mean()\n",
    "print('gradInput mean relative error:', gradInputErr * 100 .. ' %')\n",
    "local gradParamsErr = (gradParamsGold - gradParamsTest:float()):abs():sum() / \n",
    "                      gradParamsTest:nElement() / torch.abs(gradParamsGold):mean()\n",
    "print('gradParams mean relative error:', gradParamsErr * 100 .. ' %')\n",
    "\n",
    "assert(forwardErr    < 1e-6)\n",
    "assert(gradInputErr  < 1e-6)\n",
    "assert(gradParamsErr < 7e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test multi-channel vs single-channel `Integral`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "./Integral-cuda-multi.lua:31: C/lib/libintegral-cuda.so: cannot open shared object file: No such file or directory\nstack traceback:\n\t[C]: in function 'load'\n\t./Integral-cuda-multi.lua:31: in main chunk\n\t[C]: in function 'require'\n\t[string \"local nInputCh = 5...\"]:36: in main chunk\n\t[C]: in function 'xpcall'\n\t...ubb/Programs/Torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ubb/Programs/Torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ubb/Programs/Torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t.../Programs/Torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t.../Programs/Torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t.../Programs/Torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ubb/Programs/Torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00405e40",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "./Integral-cuda-multi.lua:31: C/lib/libintegral-cuda.so: cannot open shared object file: No such file or directory\nstack traceback:\n\t[C]: in function 'load'\n\t./Integral-cuda-multi.lua:31: in main chunk\n\t[C]: in function 'require'\n\t[string \"local nInputCh = 5...\"]:36: in main chunk\n\t[C]: in function 'xpcall'\n\t...ubb/Programs/Torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ubb/Programs/Torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ubb/Programs/Torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t.../Programs/Torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t.../Programs/Torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t.../Programs/Torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ubb/Programs/Torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00405e40"
     ]
    }
   ],
   "source": [
    "local nInputCh = 5\n",
    "local nWindows = 7\n",
    "\n",
    "require 'image'\n",
    "torch.manualSeed(3)\n",
    "local input = torch.rand(nInputCh, 234, 234)\n",
    "\n",
    "Integral = nil\n",
    "debug.getregistry()['Integral'] = nil \n",
    "package.loaded['Integral-c'] = nil\n",
    "package.loaded['Integral-c-multi'] = nil\n",
    "package.loaded['Integral-jit'] = nil\n",
    "package.loaded['Integral-jit-multi'] = nil\n",
    "package.loaded['Integral-cuda-multi'] = nil\n",
    "require 'Integral-jit-multi'\n",
    "\n",
    "-- compute true forward result for some data\n",
    "local intGold = Integral(nWindows, 234, 234)\n",
    "local params, gradParamsGold = intGold:getParameters()\n",
    "\n",
    "local forwardGold = torch.Tensor(nInputCh*nWindows, 234, 234)\n",
    "for i = 1,nInputCh do\n",
    "    forwardGold[{{(i-1)*nWindows+1, i*nWindows}}]:copy(intGold:forward(input[i]))\n",
    "end\n",
    "\n",
    "-- remove the single-channel class\n",
    "Integral = nil\n",
    "debug.getregistry()['Integral'] = nil \n",
    "package.loaded['Integral-c'] = nil\n",
    "package.loaded['Integral-c-multi'] = nil\n",
    "package.loaded['Integral-jit'] = nil\n",
    "package.loaded['Integral-jit-multi'] = nil\n",
    "package.loaded['Integral-cuda-multi'] = nil\n",
    "\n",
    "-- require the new multi-channel class\n",
    "require 'Integral-cuda-multi'\n",
    "\n",
    "local intTest = Integral(nWindows, 234, 234)\n",
    "for i,member in ipairs{'xMin','xMax','yMin','yMax'} do\n",
    "    intTest[member] = intGold[member]\n",
    "end\n",
    "intTest:recalculateArea()\n",
    "\n",
    "local forwardTest = intTest:forward(input)\n",
    "\n",
    "local forwardErr = (forwardGold - forwardTest):abs():sum() / \n",
    "                   forwardTest:nElement() / torch.abs(forwardGold):mean()\n",
    "print('Output mean relative error:', forwardErr * 100 .. ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nParam = (not nParam or nParam == 5) and 1 or nParam + 1\n",
    "print(nParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "100\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Integral = nil\n",
    "IntegralSmartNorm = nil\n",
    "debug.getregistry()['Integral'] = nil \n",
    "debug.getregistry()['IntegralSmartNorm'] = nil \n",
    "package.loaded['Integral-c'] = nil\n",
    "package.loaded['Integral-c-multi'] = nil\n",
    "package.loaded['Integral-jit'] = nil\n",
    "package.loaded['Integral-jit-multi'] = nil\n",
    "package.loaded['Integral-cuda-multi'] = nil\n",
    "package.loaded['IntegralSmartNorm'] = nil\n",
    "require 'IntegralSmartNorm'\n",
    "\n",
    "Integral = IntegralSmartNorm\n",
    "\n",
    "local nInputCh = 1\n",
    "local nWindows = 2\n",
    "local imSize = 6\n",
    "\n",
    "torch.manualSeed(666)\n",
    "input = image.convolve(torch.rand(nInputCh, imSize, imSize):pow(3), \n",
    "                                image.gaussian(math.max(1,imSize/3)), 'same')\n",
    "target = image.convolve(torch.rand(nInputCh*nWindows, imSize, imSize):pow(3), \n",
    "                                image.gaussian(math.max(1,imSize/3)), 'same')\n",
    "\n",
    "int = Integral(nWindows, imSize, imSize)\n",
    "int.exact = true\n",
    "\n",
    "net = int\n",
    "int.xMin[1] = 0\n",
    "int.xMax[1] = 0\n",
    "int.yMin[1] = 0\n",
    "int.yMax[1] = 0\n",
    "\n",
    "-- int.xMin[2] = -0.9\n",
    "-- int.xMax[2] = 1.75\n",
    "-- int.yMin[2] = -0.2\n",
    "-- int.yMax[2] = -0.4\n",
    "\n",
    "-- require 'nn'\n",
    "-- net = nn.Sequential()\n",
    "-- net:add(int)\n",
    "-- net:add(nn.SpatialConvolutionMM(nInputCh*nWindows, 3, 1, 1, 1, 1)) \n",
    "-- net:add(nn.LeakyReLU(0.01))\n",
    "-- net:add(Integral(4, imSize, imSize))\n",
    "-- net:add(nn.SpatialConvolutionMM(3*4, 8, 1, 1, 1, 1))\n",
    "-- net:add(nn.Reshape(8, imSize*imSize))\n",
    "-- net:add(nn.Transpose({2, 1}))\n",
    "\n",
    "-- target = torch.IntTensor(imSize*imSize)\n",
    "-- target:apply(function() return torch.random(8) end)\n",
    "\n",
    "crit = nn.MSECriterion()\n",
    "-- crit = nn.CrossEntropyCriterion()\n",
    "\n",
    "param = {}\n",
    "loss = {}\n",
    "dL_dParam_nn = {}\n",
    "dL_dParam_diff = {}\n",
    "\n",
    "-- nParam = 1 -- 1,2,3,4 <-> xMax,yMax,xMin,yMin\n",
    "\n",
    "if -- ***********************\n",
    "nParam == 1 then int.xMax[1] = 60 elseif\n",
    "nParam == 2 then int.yMax[1] = 60 elseif\n",
    "nParam == 3 then int.xMin[1] = -60 elseif\n",
    "nParam == 4 then int.yMin[1] = -60 end\n",
    "\n",
    "-- int:recalculateArea()\n",
    "\n",
    "local stepSize = 1\n",
    "local maxStep = 100\n",
    "\n",
    "for i = 1,maxStep do\n",
    "    if -- ***************************\n",
    "    nParam == 1 then param[i] = int.xMax[1] - maxStep + i elseif\n",
    "    nParam == 2 then param[i] = int.yMax[1] - maxStep + i elseif\n",
    "    nParam == 3 then param[i] = int.xMin[1] + i - 1 elseif\n",
    "    nParam == 4 then param[i] = int.yMin[1] + i - 1 elseif\n",
    "    nParam == 5 then param[i] = -100 + i*stepSize end\n",
    "    \n",
    "    loss[i] = -666\n",
    "    dL_dParam_nn[i] = -666\n",
    "    dL_dParam_diff[i] = -666\n",
    "end\n",
    "\n",
    "for i = 1,#param do\n",
    "    net:zeroGradParameters()\n",
    "    \n",
    "    if -- ***************************\n",
    "    nParam == 1 then int.xMin[1] = param[i] elseif\n",
    "    nParam == 2 then int.yMin[1] = param[i] elseif\n",
    "    nParam == 3 then int.xMax[1] = param[i] elseif\n",
    "    nParam == 4 then int.yMax[1] = param[i] elseif\n",
    "    nParam == 5 then input[{1,3,3}] = param[i] end\n",
    "    \n",
    "--     int:recalculateArea()\n",
    "    \n",
    "    pred = net:forward(input)\n",
    "    \n",
    "    currLoss = crit:forward(pred, target)\n",
    "    dLoss_dOutput = crit:backward(pred, target)\n",
    "    net:backward(input, dLoss_dOutput)\n",
    "    \n",
    "    loss[i] = currLoss\n",
    "    \n",
    "    if -- ***************************\n",
    "    nParam == 1 then dL_dParam_nn[i] = int.gradXMin[1] elseif\n",
    "    nParam == 2 then dL_dParam_nn[i] = int.gradYMin[1] elseif\n",
    "    nParam == 3 then dL_dParam_nn[i] = int.gradXMax[1] elseif\n",
    "    nParam == 4 then dL_dParam_nn[i] = int.gradYMax[1] elseif\n",
    "    nParam == 5 then dL_dParam_nn[i] = int.gradInput[{1,3,3}] end\n",
    "    \n",
    "    -- step forward a bit\n",
    "    local innerStepSize = 0.1\n",
    "    if -- ***************************\n",
    "    nParam == 1 then int.xMin[1] = int.xMin[1] + innerStepSize elseif\n",
    "    nParam == 2 then int.yMin[1] = int.yMin[1] + innerStepSize elseif\n",
    "    nParam == 3 then int.xMax[1] = int.xMax[1] + innerStepSize elseif\n",
    "    nParam == 4 then int.yMax[1] = int.yMax[1] + innerStepSize elseif\n",
    "    nParam == 5 then input[{1,3,3}] = param[i] + innerStepSize end\n",
    "    \n",
    "--     int:recalculateArea()\n",
    "    \n",
    "    pred = net:forward(input)\n",
    "    currLoss = crit:forward(pred, target)\n",
    "    dLoss_dOutput = crit:backward(pred, target)\n",
    "    gradInput = net:backward(input, dLoss_dOutput)\n",
    "    \n",
    "    dL_dParam_diff[i] = (currLoss - loss[i]) / innerStepSize\n",
    "    \n",
    "    collectgarbage()\n",
    "    \n",
    "    if i % 50 == 0 then print(i) end\n",
    "end\n",
    "\n",
    "for i = 1,#param-1 do\n",
    "--     dL_dParam_diff[i] = (loss[i+1] - loss[i]) / stepSize\n",
    "end\n",
    "\n",
    "param[#param] = nil\n",
    "dL_dParam_nn[#dL_dParam_nn] = nil\n",
    "dL_dParam_diff[#dL_dParam_diff] = nil\n",
    "loss[#loss] = nil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function round_down(x)\n",
    "    local rounded = math.floor(x)\n",
    "    return rounded, x-rounded -- return integer and fractional parts\n",
    "end\n",
    "\n",
    "function round_up(x)\n",
    "    local rounded = math.ceil(x)\n",
    "    return rounded, rounded-x -- return integer and fractional parts\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int.xMin[2] = -0.9\n",
    "int.xMax[2] = 0.75\n",
    "int.yMin[2] = -0.7\n",
    "int.yMax[2] = -0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int.debug = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xMin = 0, xMax = 1\n",
       "yMin = 0, yMax = 1\n",
       "integral location: 0.1\n",
       "xMax frac: 0.0141307 * 0\n",
       "yMax frac: 0.339036 * 0\n",
       "xMin frac: 0.693987 * 0\n",
       "yMin frac: 0.329742 * 0\n",
       "xMax,yMax corner = 0.177209 * 0\n",
       "xMin,yMax corner = 0.555608 * 0\n",
       "xMax,yMin corner = 0.0854067 * 0\n",
       "xMin,yMin corner = 0.424076 * 0\n",
       "\n",
       "xMin = 0, xMax = 1\n",
       "yMin = 0, yMax = 0\n",
       "integral location: 0\n",
       "xMax frac: 0 * 0.75\n",
       "yMax frac: 0.1 * 0.6\n",
       "xMin frac: -2.98023e-08 * 0.9\n",
       "yMin frac: 0.329742 * 0.7\n",
       "xMax,yMax corner = 0.0141308 * 0.45\n",
       "xMin,yMax corner = 0.693987 * 0.54\n",
       "xMax,yMin corner = 0.0854067 * 0.525\n",
       "xMin,yMin corner = 0.424076 * 0.63\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1,.,.) = \n",
       "  0.1264  0.1268  0.2217  0.2248  0.1174  0.1147\n",
       "  0.2683  0.4241  0.6940  0.5556  0.1313  0.1201\n",
       "  0.1679  0.3297  0.1000  0.3390  0.0225  0.0422\n",
       "  0.0743  0.0854  0.0141  0.1772  0.3262  0.3912\n",
       "  0.0509  0.0787  0.1574  0.3073  0.3386  0.3651\n",
       "  0.1735  0.3425  0.2956  0.2823  0.1655  0.2434\n",
       "\n",
       "(2,.,.) = \n",
       "  0.1966  0.4963  0.7567  0.9044  0.5786  0.2740\n",
       "  0.3048  0.8269  1.0511  1.1456  0.7192  0.2567\n",
       "  0.2790  0.7908  0.7173  0.7329  0.6355  0.5948\n",
       "  0.1581  0.4492  0.2383  0.5958  0.7283  1.1779\n",
       "  0.1487  0.4210  0.4963  0.6991  0.8313  1.0773\n",
       "  0.1316  0.4015  0.6528  0.7887  0.6853  0.5707\n",
       "[torch.FloatTensor of size 2x6x6]\n",
       "\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int:forward(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2908194\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(0.1 * 0.6 + 0.329742 * 0.7) --  + 0.0141308 * 0.45 + 0.693987 * 0.54 + 0.0854067 * 0.525 + 0.424076 * 0.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9839383661747\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = input[1]\n",
    "row = m[2] * 0.9 + m[3] + m[4] * 0.75\n",
    "print(row[2] * 0.7 + row[3] * 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'gnuplot'\n",
    "\n",
    "gnuplot.figure(2)\n",
    "gnuplot.plot{\n",
    "    {'manual', torch.Tensor(param), torch.Tensor(dL_dParam_nn), '-'},\n",
    "    {'diff'  , torch.Tensor(param), torch.Tensor(dL_dParam_diff), '-'},\n",
    "--     {'zero'  , torch.Tensor{0, 0}, torch.Tensor{torch.Tensor(dL_dParam_diff):min(), torch.Tensor(dL_dParam_diff):max()}, '-'},\n",
    "--     {'loss'  , torch.Tensor(param), torch.Tensor(loss), '-'},\n",
    "}\n",
    "gnuplot.movelegend('right', 'middle')\n",
    "gnuplot.xlabel('parameter')\n",
    "gnuplot.ylabel('dLoss / dParameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure execution times\n",
    "\n",
    "Input: 1024x768 image\n",
    "\n",
    "* **Forward** experiment: compute `16x1024x768` feature maps 4 times\n",
    "* **Backward** experiment: do a backprop step (from the \"after `Forward`\" state) 4 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward\n",
    "\n",
    "* $2.993 \\pm 0.242$ sec. (LuaJIT loop + exact fractional parts computation)\t\n",
    "* $0.487 \\pm 0.087$ sec. (LuaJIT loop)\n",
    "* $0.358 \\pm 0.019$ sec. (C loop)\n",
    "* $0.321 \\pm 0.037$ sec. (+ precomputed `t,b,l,r`)\n",
    "* $0.165 \\pm 0.058$ sec. (+ parallel)\n",
    "* $0.140 \\pm 0.066$ sec. (+ inline `areaCoeff` multiplication)\n",
    "* $0.048 \\pm 0.032$ sec. (after GPU modifications, i dunno why lol)\n",
    "\n",
    "*CUDA, GTX 970*\n",
    "\n",
    "* $0.03152 \\pm 0.0084$ sec. ('single' kernel)\n",
    "* $0.03481 \\pm 0.0081$ sec. ('multi' kernel, block size = 1x32x32)\n",
    "* $0.08079 \\pm 0.0123$ sec. ('multi' kernel, block size = 4x16x16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward\n",
    "\n",
    "* $2.660 \\pm 0.252$ sec. (LuaJIT)\n",
    "* $1.956 \\pm 0.385$ sec. (C parallel `updGI`)\n",
    "* $1.616 \\pm 0.274$ sec. (+ C gradParam loop, precomputed `t,b,l,r`)\n",
    "* $1.357 \\pm 0.136$ sec. (+ parallelize by deltas -- 2 threads)\n",
    "* $1.991 \\pm 0.358$ sec. (+ parallelize by deltas -- 4 threads)\n",
    "* $1.576 \\pm 0.290$ sec. (+ parallelize by rows)\n",
    "* $1.103 \\pm 0.179$ sec. (after GPU modifications, i dunno why lol)\n",
    "\n",
    "*CUDA, GTX 970*\n",
    "\n",
    "* $0.5923 \\pm 0.0413$ sec. (parallelized only `forward` (*affects `updateGradInput`*) with 'multi' kernel, block size = 1x32x32)\n",
    "* $0.3409 \\pm 0.0144$ sec. (+ parallel `backward`, 'single' kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Integral = nil\n",
    "debug.getregistry()['Integral'] = nil \n",
    "package.loaded['Integral-c'] = nil\n",
    "package.loaded['Integral-c-multi'] = nil\n",
    "package.loaded['Integral-jit'] = nil\n",
    "package.loaded['Integral-jit-multi'] = nil\n",
    "package.loaded['Integral-cuda-multi'] = nil\n",
    "require 'Integral-cuda-multi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = 768\n",
    "w = 1024\n",
    "nMaps = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int = Integral(nMaps, h, w):cuda()\n",
    "params, gradParams = int:getParameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03714292049408 +/- 0.012073122348821 seconds\t\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.rand(h, w):type(int:type())\n",
    "local repeats = 4\n",
    "local timeRepeats = 20\n",
    "\n",
    "int:forward(img)\n",
    "\n",
    "times = torch.Tensor(timeRepeats)\n",
    "\n",
    "for timeRepeat = 1,timeRepeats do\n",
    "\n",
    "    local timer = torch.Timer()\n",
    "\n",
    "    for _ = 1,repeats do\n",
    "        int:forward(img)\n",
    "    end\n",
    "\n",
    "    cutorch.synchronize()\n",
    "    timer:stop()\n",
    "\n",
    "    times[timeRepeat] = timer:time().real\n",
    "    \n",
    "    collectgarbage()\n",
    "end\n",
    "\n",
    "print(times:mean() .. ' +/- ' .. 2.1 * times:std() .. ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34089180628459 +/- 0.014416537071796 seconds\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.rand(h, w):type(int:type())\n",
    "local repeats = 4\n",
    "local timeRepeats = 15\n",
    "\n",
    "times = torch.Tensor(timeRepeats)\n",
    "\n",
    "local prediction = int:forward(img)\n",
    "int:backward(img, prediction)\n",
    "\n",
    "for timeRepeat = 1,timeRepeats do\n",
    "\n",
    "    local timer = torch.Timer()\n",
    "\n",
    "    for _ = 1,repeats do\n",
    "        int:backward(img, prediction)\n",
    "    end\n",
    "\n",
    "    cutorch.synchronize()\n",
    "    timer:stop()\n",
    "\n",
    "    times[timeRepeat] = timer:time().real\n",
    "    \n",
    "    collectgarbage()\n",
    "    \n",
    "end\n",
    "\n",
    "print(times:mean() .. ' +/- ' .. 2.1 * times:std() .. ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
