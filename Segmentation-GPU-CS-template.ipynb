{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.setdefaulttensortype('torch.FloatTensor')\n",
    "require 'cutorch'\n",
    "\n",
    "exact = true\n",
    "separateParams = false\n",
    "GPUs = {1,2,3,4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Cityscapes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading images from /media/hpc4_Raid/e_burkov/Datasets/Cityscapes/leftImg8bit/train/. Example cities: hanover, tubingen\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Loading images from /media/hpc4_Raid/e_burkov/Datasets/Cityscapes/leftImg8bit/val/. Example cities: lindau, ..\t\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package.loaded.cityscapes = nil\n",
    "cityscapes = require 'cityscapes'\n",
    "\n",
    "cityscapes.relative = '/media/hpc4_Raid/e_burkov/Datasets/Cityscapes/'\n",
    "nClasses = cityscapes.nClasses -- 19\n",
    "\n",
    "trainFiles = cityscapes.loadNames('train')\n",
    "valFiles = cityscapes.loadNames('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'cunn'\n",
    "require 'cudnn'\n",
    "\n",
    "if #GPUs > 1 then\n",
    "    local function bnparams(self)\n",
    "       local p, gp = nn.Module.parameters(self)\n",
    "        p[#p+1] = self.running_mean\n",
    "        p[#p+1] = self.running_var\n",
    "        gp[#gp+1] = self.running_mean:clone():zero()\n",
    "        gp[#gp+1] = self.running_var:clone():zero()\n",
    "        return p, gp\n",
    "    end\n",
    "\n",
    "    torch.getconstructortable('nn.BatchNormalization').parameters = bnparams\n",
    "    torch.getconstructortable('cudnn.BatchNormalization').parameters = bnparams\n",
    "end\n",
    "\n",
    "cudnn.fastest = true\n",
    "cudnn.benchmark = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelName = '086-enet-int-debugged'\n",
    "cityscapes.dsize = {1024, 512}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render labels for displaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "-- example blending\n",
    "local k = 19\n",
    "local img, labels = cityscapes.loadSample(trainFiles[k])\n",
    "itorch.image(cityscapes.renderLabels(labels, img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intKind = 'IntegralSmartNorm'\n",
    "_G[intKind] = nil\n",
    "debug.getregistry()[intKind] = nil \n",
    "package.loaded[intKind] = nil\n",
    "\n",
    "require(intKind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Number of IntegralSmartNorm modules: 8\t\n",
       "Number of group sparsity regularized modules: 0\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local modelName = modelName\n",
    "net, GSconfig = \n",
    "    assert(loadfile('Models/' .. modelName .. '.lua'))(cityscapes.dsize[1], cityscapes.dsize[2], nClasses)\n",
    "\n",
    "if not torch.type(net:get(#net)):find('LogSoftMax') then\n",
    "    net:add(nn.Contiguous())\n",
    "    net:add(nn.View(-1, nClasses))\n",
    "    net:add(nn.LogSoftMax())\n",
    "end\n",
    "\n",
    "ints = net:findModules(intKind)\n",
    "for i = 1,#ints do\n",
    "    ints[i].normalize = true\n",
    "    ints[i].exact = exact\n",
    "    ints[i].saveMemoryIntegral = false\n",
    "end\n",
    "print('Number of IntegralSmartNorm modules: ' .. #ints)\n",
    "print('Number of group sparsity regularized modules: ' .. #GSconfig)\n",
    "\n",
    "net:cuda()\n",
    "collectgarbage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "math.randomseed(666)\n",
    "torch.manualSeed(666)\n",
    "if CUDA then cutorch.manualSeed(666) end\n",
    "\n",
    "if #GPUs > 1 then\n",
    "    net = nn.DataParallelTable(1, true, true):threads(\n",
    "        function()\n",
    "            require 'cudnn'\n",
    "            require 'IntegralSmartNorm'\n",
    "        end)\n",
    "        :cuda():add(net, GPUs)\n",
    "end\n",
    "\n",
    "net:reset()\n",
    "\n",
    "if separateParams then\n",
    "    params, gradParams = net:parameters()\n",
    "else\n",
    "    params, gradParams = net:getParameters()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'optim'\n",
    "\n",
    "datasetIdx = 1\n",
    "\n",
    "if separateParams then\n",
    "    optimStates = {}\n",
    "\n",
    "    local intParamsCount = 0\n",
    "\n",
    "    for i = 1,#params do\n",
    "        optimStates[i] = {\n",
    "            learningRate = 1e-3,\n",
    "            momentum = 0.9,\n",
    "            nesterov = true,\n",
    "            dampening = 0,\n",
    "            learningRateDecay = 0,\n",
    "            weightDecay = 2e-4\n",
    "        }\n",
    "\n",
    "        for k = 1,#ints do\n",
    "            if \n",
    "                params[i] == ints[k].xMin or\n",
    "                params[i] == ints[k].xMax or\n",
    "                params[i] == ints[k].yMin or\n",
    "                params[i] == ints[k].yMax then\n",
    "\n",
    "                ints[k].params = ints[k].params or {}\n",
    "                table.insert(ints[k].params, i)\n",
    "\n",
    "                optimStates[i].weightDecay = 2e-4 -- 0.0185\n",
    "                optimStates[i].learningRate = optimStates[i].learningRate\n",
    "                intParamsCount = intParamsCount + 1\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "\n",
    "        for k = 1,#GSconfig do\n",
    "            assert(torch.type(GSconfig[k].haarConv):find('Convolution'))\n",
    "            assert(torch.type(GSconfig[k].int):find('Integral'))\n",
    "            assert(torch.type(GSconfig[k].bn):find('SpatialBatchNorm'))\n",
    "\n",
    "            GSconfig[k].bnMedGamma = 1\n",
    "            GSconfig[k].bnMedBeta = 0\n",
    "\n",
    "            if params[i] == GSconfig[k].haarConv.weight then\n",
    "                optimStates[i].GSconfigIdx = k\n",
    "    --             optimStates[i].haarConv = haarConvs[k]\n",
    "    --             optimStates[i].int = assert(ints[k])\n",
    "    --             optimStates[i].bn = assert(optimStates[i].haarConv.bn)\n",
    "\n",
    "                -- let us add WD manually\n",
    "                optimStates[i].weightDecayL2 = optimStates[i].weightDecay\n",
    "                -- don't let `optim` optimizer do it\n",
    "                optimStates[i].weightDecay = 0\n",
    "\n",
    "                optimStates[i].weightDecayGS = 1e-3 -- need to tune\n",
    "                optimStates[i].groupSparsityTensor = params[i]:clone()\n",
    "                optimStates[i].tmpSumTensor = params[i].new(params[i]:size(1), 1, 1, 1)\n",
    "            elseif params[i] == GSconfig[k].bn.weight or params[i] == GSconfig[k].bn.bias then\n",
    "                GSconfig[k].bn.params = GSconfig[k].bn.params or {}\n",
    "                table.insert(GSconfig[k].bn.params, i)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    print('Number of IntegralSmartNorm parameter tensors: ' .. intParamsCount)\n",
    "else\n",
    "    optimStates = {\n",
    "        learningRate = 1e-3,\n",
    "        momentum = 0.9,\n",
    "        nesterov = true,\n",
    "        dampening = 0,\n",
    "        learningRateDecay = 0,\n",
    "        weightDecay = 2e-4\n",
    "    }\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputDir = 'Cityscapes segmentation/' .. modelName .. '/001/'\n",
    "os.execute('mkdir \"' .. outputDir .. 'Images/train\" -p')\n",
    "os.execute('mkdir \"' .. outputDir .. 'Images/val\" -p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- do return end\n",
    "\n",
    "for k = 1,#ints do\n",
    "    for p = 1,ints[k].xMin:nElement() do\n",
    "        ints[k]:resetSingleWindow(p)\n",
    "    end\n",
    "    ints[k].xMin:mul(1.5)\n",
    "    ints[k].xMax:mul(1.5)\n",
    "    ints[k].yMin:mul(1.5)\n",
    "    ints[k].yMax:mul(1.5)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Load a saved model\n",
    "do return end\n",
    "require 'nngraph'\n",
    "require 'cunn'\n",
    "require 'cudnn'\n",
    "\n",
    "net, optimStates, GSconfig = table.unpack(torch.load(outputDir .. 'net.t7'))\n",
    "\n",
    "if not torch.type(net:get(#net)):find('LogSoftMax') then\n",
    "    net:add(nn.Contiguous())\n",
    "    net:add(nn.View(-1, nClasses))\n",
    "    net:add(nn.LogSoftMax())\n",
    "end\n",
    "\n",
    "net:cuda()\n",
    "ints = net:findModules(intKind)\n",
    "for i = 1,#ints do\n",
    "    ints[i].normalize = true\n",
    "    ints[i].exact = exact\n",
    "end\n",
    "\n",
    "require 'optim'\n",
    "\n",
    "loaded = true\n",
    "\n",
    "if #GPUs > 1 then\n",
    "    net = nn.DataParallelTable(1, true, true):threads(\n",
    "        function()\n",
    "            require 'cudnn'\n",
    "            require 'IntegralSmartNorm'\n",
    "        end)\n",
    "        :cuda():add(net, GPUs)\n",
    "end\n",
    "\n",
    "if separateParams then\n",
    "    params, gradParams = net:parameters()\n",
    "else\n",
    "    params, gradParams = net:getParameters()\n",
    "end\n",
    "\n",
    "datasetIdx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "package.loaded.WindowDebugger = nil\n",
    "debug.getregistry().WindowDebugger = nil\n",
    "WindowDebugger = nil\n",
    "\n",
    "require 'WindowDebugger'\n",
    "\n",
    "-- ints = {1,1,1,1,1,1,1,1}\n",
    "wDebs = (#ints > 0) and {} or nil\n",
    "for k = 1,#ints do wDebs[k] = WindowDebugger() end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'optim'\n",
    "\n",
    "onlineLossLogger = optim.Logger(outputDir .. 'onlineLossLog.log')\n",
    "evalLogger = optim.Logger(outputDir .. 'evalLog.log')\n",
    "evalAccLogger = optim.Logger(outputDir .. 'evalAccLog.log')\n",
    "\n",
    "onlineLossLogger:setNames{'Online batch loss'}\n",
    "evalLogger:setNames{'Train loss', 'Validation loss'}\n",
    "evalAccLogger:setNames{\n",
    "    'Train IoU class', 'Train IoU category',\n",
    "    'Validation IoU class', 'Validation IoU category'}\n",
    "\n",
    "onlineLossLogger:style{'-'}\n",
    "evalLogger:style{'-', '-'}\n",
    "evalAccLogger:style{'-', '-', '-', '-'}\n",
    "\n",
    "onlineLossLogger.showPlot = false\n",
    "evalLogger.showPlot = false\n",
    "evalAccLogger.showPlot = false\n",
    "\n",
    "haarConvLoggers = {}\n",
    "for k = 1,#GSconfig do\n",
    "    haarConvLoggers[k] = optim.Logger(outputDir .. 'haarConv' .. k .. 'Log.log')\n",
    "    local names, styles = {}, {}\n",
    "    for i = GSconfig[k].l,GSconfig[k].r do\n",
    "        table.insert(names, tostring(i))\n",
    "        table.insert(styles, '-')\n",
    "    end\n",
    "    haarConvLoggers[k]:setNames(names)\n",
    "    haarConvLoggers[k]:style(styles)\n",
    "    haarConvLoggers[k].plotRawCmd = 'unset key'\n",
    "    haarConvLoggers[k].showPlot = false\n",
    "end\n",
    "\n",
    "haarConvZeroCountLogger = optim.Logger(outputDir .. 'haarConvZeroCountLog.log')\n",
    "local names, styles = {}, {}\n",
    "for k = 1,#GSconfig do\n",
    "    table.insert(names, tostring(k))\n",
    "    table.insert(styles, '-')\n",
    "end\n",
    "haarConvZeroCountLogger:setNames(names)\n",
    "haarConvZeroCountLogger:style(styles)\n",
    "haarConvZeroCountLogger.showPlot = false\n",
    "\n",
    "function needToPlot(_onlineLossLogger)\n",
    "    local plotFreq = 10\n",
    "    local count = #_onlineLossLogger.symbols[1] + 1\n",
    "    while count > 1000 do\n",
    "        plotFreq = plotFreq * 10\n",
    "        count = count / 10\n",
    "    end\n",
    "    \n",
    "    return #_onlineLossLogger.symbols[1] % plotFreq == 0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k = 1,#ints do\n",
    "    if wDebs and loaded and paths.filep(outputDir .. 'wd' .. k .. '.t7') then\n",
    "        wDebs[k]:load(outputDir .. 'wd' .. k .. '.t7')\n",
    "    end\n",
    "end\n",
    "\n",
    "if loaded and paths.filep(outputDir .. 'evalLogger.t7') then\n",
    "    evalLogger.symbols = torch.load(outputDir .. 'evalLogger.t7')\n",
    "end\n",
    "if loaded and paths.filep(outputDir .. 'evalAccLogger.t7') then\n",
    "    evalAccLogger.symbols = torch.load(outputDir .. 'evalAccLogger.t7')\n",
    "end\n",
    "if loaded and paths.filep(outputDir .. 'onlineLossLogger.t7') then\n",
    "    onlineLossLogger.symbols = torch.load(outputDir .. 'onlineLossLogger.t7')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "do return end\n",
    "\n",
    "-- Measure forward/backward propagation time\n",
    "input = batch --torch.CudaTensor(5, 3, cityscapes.dsize[2], cityscapes.dsize[1]):fill(0.1)\n",
    "local exactTest = true\n",
    "net:evaluate()\n",
    "\n",
    "for k = 1,#ints do\n",
    "    ints[k].exact = exactTest\n",
    "end\n",
    "\n",
    "timer = torch.Timer()\n",
    "for k = 1,5 do\n",
    "    net:forward(input)\n",
    "--     net:backward(input, net.output:clone())\n",
    "end\n",
    "cutorch.synchronize()\n",
    "\n",
    "for k = 1,#ints do\n",
    "    ints[k].exact = exact\n",
    "end\n",
    "\n",
    "print('Average time for 1 forward pass: ' .. (timer:time().real) .. ' seconds. Output size:')\n",
    "print(net.output:size())\n",
    "\n",
    "collectgarbage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.ClassNLLCriterion(cityscapes.classWeights, true, 255):cuda()\n",
    "-- criterion.nll.ignoreIndex = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function predict(net, example)\n",
    "    local pred = net:forward(nn.utils.addSingletonDimension(example:type(net.modules[1]:type())))\n",
    "    return select(2, pred[1]:view(cityscapes.dsize[2], cityscapes.dsize[1], nClasses):max(3)):squeeze():float()\n",
    "end\n",
    "\n",
    "function comparePredictions(imgIn, labels, prediction, omitOriginal)\n",
    "    -- tmp buffer for comparePredictions()\n",
    "    local img = torch.FloatTensor(3, cityscapes.dsize[2], cityscapes.dsize[1])\n",
    "    img:copy(imgIn)\n",
    "\n",
    "    img:add(-img:min())\n",
    "    img:div(img:max())\n",
    "\n",
    "    local retval\n",
    "\n",
    "    if omitOriginal then\n",
    "        retval = torch.ones(3, img:size(2)*2 + 2, img:size(3))\n",
    "\n",
    "        retval[{{}, {1, img:size(2)}, {}}]:copy(cityscapes.renderLabels(labels, img))\n",
    "        retval[{{}, {img:size(2)+3, img:size(2)*2+2}, {}}]:copy(cityscapes.renderLabels(prediction, img))\n",
    "    else\n",
    "        retval = torch.ones(3, img:size(2)*3 + 4, img:size(3))\n",
    "        retval[{{}, {1, img:size(2)}, {}}]:copy(img)\n",
    "        retval[{{}, {img:size(2)+3, img:size(2)*2+2}, {}}]:copy(cityscapes.renderLabels(labels, img, 0.8))\n",
    "        retval[{{}, {img:size(2)*2+5, retval:size(2)}, {}}]:copy(cityscapes.renderLabels(prediction, img, 0.8))\n",
    "    end\n",
    "\n",
    "    collectgarbage()\n",
    "\n",
    "    return retval\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluationIdxVal = {\n",
    "    025, 050, 075, 100, 125, 150, 175, 200, 225, 250, \n",
    "    275, 300, 325, 350, 375, 400, 425, 450, 475, 500\n",
    "}\n",
    "\n",
    "evaluationIdxTrain = {\n",
    "    0150, 0300, 0450, 0600, 0750, 0900, 1050, 1200, 1350, 1500,\n",
    "    1650, 1800, 1950, 2100, 2250, 2400, 2550, 2700, 2850, 2975\n",
    "}\n",
    "\n",
    "-- table.sort(evaluationIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function evaluate(net, files, indices, outPath)\n",
    "    local threadLog = {write=function()end, close=function()end, flush=function()end}\n",
    "    -- local threadLog = io.open(outputDir .. 'threadLog.txt', 'w')\n",
    "    \n",
    "    local losses = {}\n",
    "    local avgLoss = 0\n",
    "    local confMatrix = torch.LongTensor(cityscapes.nClasses, cityscapes.nClasses):zero()\n",
    "    \n",
    "    -- Asynchronous image loading\n",
    "    threads = require 'threads'\n",
    "    threads.serialization('threads.sharedserialize')\n",
    "    threads.Threads.serialization('threads.sharedserialize')\n",
    "    require 'Queue'\n",
    "    local queue = Queue() -- a queue of preprocessed input images\n",
    "    local qMutex = threads.Mutex()\n",
    "    queue.put = threads.safe(queue.put, qMutex)\n",
    "    queue.get = threads.safe(queue.get, qMutex)\n",
    "    local loadNThreads, saveNThreads = 4, 4\n",
    "    local nJobs = 0 -- number of images that are either in production or not yet consumed\n",
    "    \n",
    "    local _dsize, _relative = cityscapes.dsize, cityscapes.relative\n",
    "    local loadPool = threads.Threads(\n",
    "        loadNThreads,\n",
    "        function(threadId)\n",
    "            (require 'sys').sleep((threadId-1) / 24)\n",
    "            cityscapes = require 'cityscapes'\n",
    "\n",
    "            cityscapes.relative = _relative\n",
    "            cityscapes.dsize = _dsize\n",
    "            nClasses = cityscapes.nClasses -- 19\n",
    "\n",
    "            threadFiles = files\n",
    "        end,\n",
    "\n",
    "        function(threadId)\n",
    "--             print('Launching eval load thread #' .. threadId)\n",
    "        end\n",
    "    )\n",
    "    \n",
    "    local _comparePred = comparePredictions\n",
    "    local _dsize = cityscapes.dsize\n",
    "    \n",
    "    local savePool = outPath and threads.Threads(\n",
    "        saveNThreads,\n",
    "        function(threadId)\n",
    "            (require 'sys').sleep((threadId-1) / 24)\n",
    "            require 'image'\n",
    "            cityscapes = require 'cityscapes'\n",
    "            cityscapes.dsize = _dsize\n",
    "            \n",
    "            comparePred = _comparePred\n",
    "        end,\n",
    "\n",
    "        function(threadId)\n",
    "--             print('Launching thread #' .. threadId)\n",
    "        end\n",
    "    )\n",
    "    \n",
    "    local indicesIdx = 1\n",
    "    \n",
    "    for _ = 1,#indices do\n",
    "        -- add asynchronous image loading tasks\n",
    "        while indicesIdx <= #indices and nJobs < 10 do\n",
    "            threadLog:write('Add,nJobs=' .. nJobs .. '\\n'); threadLog:flush()\n",
    "            loadPool:addjob(\n",
    "                function(nextFileIdx)\n",
    "                    local input, target =\n",
    "                        cityscapes.loadSample(threadFiles[nextFileIdx])\n",
    "\n",
    "                    target = target:view(cityscapes.dsize[1]*cityscapes.dsize[2])\n",
    "\n",
    "                    collectgarbage()\n",
    "\n",
    "                    return nextFileIdx, input, target\n",
    "                end,\n",
    "\n",
    "                function(nextFileIdx, input, target)\n",
    "                    queue:put({nextFileIdx, input, target})\n",
    "                    collectgarbage()\n",
    "                end,\n",
    "                \n",
    "                indices[indicesIdx]\n",
    "            )\n",
    "            indicesIdx = indicesIdx + 1\n",
    "            nJobs = nJobs + 1\n",
    "        end\n",
    "\n",
    "        if queue:empty() then\n",
    "            threadLog:write('Q empty\\n'); threadLog:flush()\n",
    "            loadPool:dojob()\n",
    "        end\n",
    "\n",
    "        if queue:empty() then -- should never enter this\n",
    "            threadLog:write('Q empty again\\n'); threadLog:flush()\n",
    "            os.execute('touch \"' .. outputDir .. 'QEMPTY\"')\n",
    "            while queue:empty() do end\n",
    "        end\n",
    "\n",
    "        local idx, img, labels = table.unpack(queue:get())\n",
    "        nJobs = nJobs - 1\n",
    "        threadLog:write('Consume\\n'); threadLog:flush()\n",
    "        local input = img:cuda()\n",
    "        local outputs = net:forward(nn.utils.addSingletonDimension(input)):squeeze() -- 13999 x 19\n",
    "        \n",
    "        local predictedLabels = \n",
    "            select(2, outputs:view(cityscapes.dsize[2], cityscapes.dsize[1], nClasses)\n",
    "                :max(3)):squeeze():long()\n",
    "        \n",
    "        if savePool then\n",
    "            savePool:addjob(\n",
    "                function(idx, input, labels, predictedLabels)\n",
    "                    image.savePNG(\n",
    "                        outPath .. string.format('/%04d.png', idx), \n",
    "                        comparePred(input, labels, predictedLabels))\n",
    "                    collectgarbage()\n",
    "                end,\n",
    "                function() end,\n",
    "                \n",
    "                idx, img, labels, predictedLabels\n",
    "            )\n",
    "        end\n",
    "        \n",
    "        cityscapes.updateConfusionMatrix(confMatrix, predictedLabels, labels)\n",
    "        \n",
    "        labels = labels:view(cityscapes.dsize[1]*cityscapes.dsize[2])\n",
    "\n",
    "        local loss = criterion:forward(outputs, labels:view(-1):cudaByte())\n",
    "        -- dumb way to find idx\n",
    "        for i = 1,#indices do\n",
    "            if indices[i] == idx then\n",
    "                losses[i] = loss\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        avgLoss = avgLoss + loss\n",
    "    end\n",
    "    \n",
    "    local IoUclassAvg, IoUcategoryAvg = cityscapes.calcIoU(confMatrix)\n",
    "    \n",
    "    collectgarbage()\n",
    "    \n",
    "    avgLoss = avgLoss / #indices\n",
    "    \n",
    "    loadPool:terminate()\n",
    "    qMutex:free()\n",
    "    if savePool then\n",
    "        savePool:terminate()\n",
    "    end\n",
    "    threadLog:close()\n",
    "    \n",
    "    return avgLoss, IoUclassAvg, IoUcategoryAvg, losses, confMatrix\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function augment(img, labels)\n",
    "    if torch.random() % 2 == 0 then\n",
    "        img = image.flip(img, 3)\n",
    "        labels = image.flip(labels, 2)\n",
    "    else\n",
    "        labels = labels:clone()\n",
    "    end\n",
    "\n",
    "    img = imgPadder:forward(img):clone()\n",
    "    labels = labelsPadder:forward(nn.utils.addSingletonDimension(labels):float()):byte():squeeze()\n",
    "\n",
    "    local angle = (math.random() * 2 - 1) * 4.5 / 180 * math.pi\n",
    "    img = image.rotate(img, angle, 'bilinear')\n",
    "    labels = image.rotate(labels, angle, 'simple')\n",
    "\n",
    "    local scale = (math.random() * 2 - 1) * 0.11 + 1.0\n",
    "    img = image.scale(img, '*'..scale, 'bilinear')\n",
    "    labels = image.scale(labels, '*'..scale, 'simple')\n",
    "\n",
    "    local extraH, extraW = img:size(2)-cityscapes.dsize[2], img:size(3)-cityscapes.dsize[1]\n",
    "    if extraH < 0 or extraW < 0 then\n",
    "        -- upscale\n",
    "        img = image.scale(img, cityscapes.dsize[1], cityscapes.dsize[2], 'bilinear')\n",
    "        labels = image.scale(labels, cityscapes.dsize[1], cityscapes.dsize[2], 'simple')\n",
    "    else\n",
    "        -- crop\n",
    "        local padTop, padLeft = math.floor(extraH / 2), math.floor(extraW / 2)\n",
    "        local cropH, cropW = {1+padTop,padTop+cityscapes.dsize[2]}, {1+padLeft,padLeft+cityscapes.dsize[1]}\n",
    "        img = img[{{}, cropH, cropW}]:contiguous()\n",
    "        labels = labels[{cropH, cropW}]:contiguous()\n",
    "    end\n",
    "    \n",
    "    collectgarbage()\n",
    "    \n",
    "    return img, labels\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function copyConvert(obj, t)\n",
    "   local copy = {}\n",
    "   for k, v in pairs(obj) do\n",
    "      if type(v) == 'table' then\n",
    "         copy[k] = copyConvert(v, t)\n",
    "      elseif torch.isTensor(v) then\n",
    "         if k == 'output' or k == 'gradInput' then\n",
    "            copy[k] = torch.Tensor():type(t)\n",
    "         else\n",
    "            copy[k] = v:type(t)\n",
    "         end\n",
    "      elseif k == '_type' then\n",
    "         copy[k] = t\n",
    "      else\n",
    "         copy[k] = v\n",
    "      end\n",
    "   end\n",
    "   if torch.typename(obj) then\n",
    "      torch.setmetatable(copy, torch.typename(obj))\n",
    "   end\n",
    "   return copy\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching thread #1\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Launching thread #2\n",
       "Launching thread #3\n",
       "Launching thread #4\n",
       "Launching thread #5\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Launching thread #6\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Launching thread #7\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Launching thread #8\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Launching thread #9\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Launching thread #10\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Launching thread #11\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Launching thread #12\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 1\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 2\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 3\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 4\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Epoch 5\t\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- threadLog = io.open(outputDir .. 'threadLog.txt', 'w')\n",
    "threadLog = {write=function()end, close=function()end, flush=function()end}\n",
    "\n",
    "batchSize = 12\n",
    "shuffleEvery = math.ceil(#trainFiles / batchSize) -- shuffle data every `shuffleEvery` iterations\n",
    "outputFreq = 400 -- how often to output loss to `losses` table and to redraw loss graph\n",
    "imgOutputFreq = 3 -- save validation predictions as images every `outputFreq*imgOutputFreq` iterations\n",
    "saveFreq = 1200 -- how often to save `net` and `windowDebugger`s\n",
    "\n",
    "criticalWeightValue = 0.8e-2\n",
    "\n",
    "-- Asynchronous image loading\n",
    "threads = require 'threads'\n",
    "threads.serialization('threads.sharedserialize')\n",
    "threads.Threads.serialization('threads.sharedserialize')\n",
    "require 'Queue'\n",
    "local queue = Queue() -- a queue of preprocessed input images\n",
    "local qMutex = threads.Mutex()\n",
    "queue.put = threads.safe(queue.put, qMutex)\n",
    "queue.get = threads.safe(queue.get, qMutex)\n",
    "\n",
    "local nThreads = 12\n",
    "local nJobs = 0 -- number of images that are either in production or not yet consumed\n",
    "local timer = torch.Timer()\n",
    "local _dsize, _relative, _trainFiles, _augment = cityscapes.dsize, cityscapes.relative, trainFiles, augment\n",
    "\n",
    "local pool = threads.Threads(\n",
    "    nThreads,\n",
    "    function(threadId)\n",
    "        (require 'sys').sleep((threadId-1) / 7)\n",
    "        require 'image'\n",
    "        require 'Queue'\n",
    "        threadTrainFiles = _trainFiles\n",
    "        cityscapes = require 'cityscapes'\n",
    "        \n",
    "        torch.setnumthreads(1)\n",
    "        cv.setNumThreads{0}\n",
    "        \n",
    "        cityscapes.relative = _relative\n",
    "        cityscapes.dsize = _dsize\n",
    "        nClasses = cityscapes.nClasses -- 19\n",
    "        augment = _augment\n",
    "        \n",
    "        imgPadder = nn.SpatialReplicationPadding(\n",
    "            cityscapes.dsize[1] * 0.2, cityscapes.dsize[1] * 0.2,\n",
    "            cityscapes.dsize[2] * 0.2, cityscapes.dsize[2] * 0.2):float()\n",
    "        labelsPadder = imgPadder:clone()\n",
    "    end,\n",
    "\n",
    "    function(threadId)\n",
    "        print('Launching thread #' .. threadId)\n",
    "    end\n",
    ")\n",
    "\n",
    "function randomShuffle(t)\n",
    "  for i = 1,#t do\n",
    "    local j = math.random(i, #t)\n",
    "    t[i], t[j] = t[j], t[i]\n",
    "  end\n",
    "end\n",
    "\n",
    "idx = {}\n",
    "for i = 1,#trainFiles do\n",
    "    idx[i] = i\n",
    "end\n",
    "\n",
    "local avgLoss = 0\n",
    "\n",
    "net:training()\n",
    "\n",
    "collectgarbage()\n",
    "\n",
    "if not batch or batch:size(1) ~= batchSize then\n",
    "    batch = torch.CudaTensor(batchSize, 3, cityscapes.dsize[2], cityscapes.dsize[1])\n",
    "    batchLabels = torch.CudaByteTensor(batchSize, cityscapes.dsize[1]*cityscapes.dsize[2])\n",
    "    \n",
    "    batchCPU = cutorch.createCudaHostFloatTensor(batch:size())\n",
    "    batchLabelsCPU = cutorch.createCudaHostByteTensor(batchLabels:size())\n",
    "    \n",
    "    -- for async copy\n",
    "    cutorch.reserveStreams(1)\n",
    "    batchR, batchLabelsR = batch:clone(), batchLabels:clone()\n",
    "end\n",
    "\n",
    "for _ = 1,24 do\n",
    "    pool:addjob(\n",
    "        function(nextFileIdx)\n",
    "            local img, labels =\n",
    "                cityscapes.loadSample(threadTrainFiles[nextFileIdx])\n",
    "\n",
    "            img, labels = augment(img, labels)\n",
    "\n",
    "            labels[labels:eq(0)] = 255\n",
    "            labels = labels:view(cityscapes.dsize[1]*cityscapes.dsize[2])\n",
    "\n",
    "            return img, labels\n",
    "        end,\n",
    "\n",
    "        function(img, labels)\n",
    "            queue:put({img, labels})\n",
    "        end,\n",
    "\n",
    "        idx[datasetIdx]\n",
    "    )\n",
    "    datasetIdx = datasetIdx % #trainFiles + 1\n",
    "end\n",
    "\n",
    "for k = 1,batchSize do      \n",
    "    pool:dojob()\n",
    "    pool:addjob(\n",
    "        function(nextFileIdx)\n",
    "            local img, labels =\n",
    "                cityscapes.loadSample(threadTrainFiles[nextFileIdx])\n",
    "\n",
    "            img, labels = augment(img, labels)\n",
    "\n",
    "            labels[labels:eq(0)] = 255\n",
    "            labels = labels:view(cityscapes.dsize[1]*cityscapes.dsize[2])\n",
    "\n",
    "            return img, labels\n",
    "        end,\n",
    "\n",
    "        function(img, labels)\n",
    "            queue:put({img, labels})\n",
    "        end,\n",
    "\n",
    "        idx[datasetIdx]\n",
    "    )\n",
    "    datasetIdx = datasetIdx % #trainFiles + 1\n",
    "\n",
    "    if queue:empty() then -- should never enter this\n",
    "        threadLog:write('Q empty again\\n'); threadLog:flush()\n",
    "        os.execute('touch \"' .. outputDir .. 'QEMPTY\"')\n",
    "        while queue:empty() do end\n",
    "    end\n",
    "\n",
    "    local input, target = table.unpack(queue:get())\n",
    "    nJobs = nJobs - 1\n",
    "    threadLog:write('Consume\\n'); threadLog:flush()\n",
    "\n",
    "    batchCPU[k]:copy(input)\n",
    "    batchLabelsCPU[k]:copy(target)\n",
    "end\n",
    "\n",
    "batchR:copy(batchCPU)\n",
    "batchLabelsR:copy(batchLabelsCPU)\n",
    "\n",
    "-- ************** Main loop ***************\n",
    "\n",
    "for iter = 103,1e9 do\n",
    "    \n",
    "    if (iter-1) % shuffleEvery == 0 then\n",
    "        randomShuffle(idx)\n",
    "        print('Epoch ' .. ((iter-1) / shuffleEvery))\n",
    "    end\n",
    "    \n",
    "    if math.max(iter,1) % (18e2*outputFreq) == 0 then\n",
    "        local optimStatesList = separateParams and optimStates or {optimStates}\n",
    "        for k = 1,#optimStatesList do\n",
    "            optimStatesList[k].learningRate = optimStatesList[k].learningRate / 2\n",
    "            optimStatesList[k].t = 0\n",
    "            optimStatesList[k].m:zero()\n",
    "            optimStatesList[k].v:zero()\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if wDebs and (iter-1) % 200 == 0 then\n",
    "        for k = 1,#wDebs do\n",
    "            wDebs[k]:add(ints[k])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if (iter-1) % saveFreq == 0 then\n",
    "        torch.save(outputDir .. 'net.t7', \n",
    "            {copyConvert(#GPUs > 1 and net:get(1) or net, 'torch.FloatTensor'):clearState(), \n",
    "            optimStates, GSconfig})\n",
    "        \n",
    "        torch.save(outputDir .. 'evalLogger.t7', evalLogger.symbols)\n",
    "        torch.save(outputDir .. 'evalAccLogger.t7', evalAccLogger.symbols)\n",
    "        torch.save(outputDir .. 'onlineLossLogger.t7', onlineLossLogger.symbols)\n",
    "        \n",
    "        if wDebs then\n",
    "            for k = 1,#wDebs do\n",
    "                wDebs[k]:save(outputDir .. 'wd' .. k .. '.t7')\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    local batchLoss = 0 -- at current minibatch\n",
    "    \n",
    "    -- forward + backward\n",
    "    do\n",
    "        threadLog:write('other time: ' .. timer:time().real .. '\\n'); threadLog:flush(); timer:reset()\n",
    "        \n",
    "        -- start filling 'standby' batch\n",
    "        cutorch.streamSynchronize(1)\n",
    "        batch, batchR = batchR, batch\n",
    "        batchLabels, batchLabelsR = batchLabelsR, batchLabels\n",
    "        \n",
    "        threadLog:write('sync time: ' .. timer:time().real .. '\\n'); threadLog:flush(); timer:reset()\n",
    "        \n",
    "        for k = 1,batchSize do      \n",
    "            pool:dojob()\n",
    "            pool:addjob(\n",
    "                function(nextFileIdx)\n",
    "                    local img, labels =\n",
    "                        cityscapes.loadSample(threadTrainFiles[nextFileIdx])\n",
    "\n",
    "                    img, labels = augment(img, labels)\n",
    "\n",
    "                    labels[labels:eq(0)] = 255\n",
    "                    labels = labels:view(cityscapes.dsize[1]*cityscapes.dsize[2])\n",
    "\n",
    "                    return img, labels\n",
    "                end,\n",
    "\n",
    "                function(img, labels)\n",
    "                    queue:put({img, labels})\n",
    "                end,\n",
    "\n",
    "                idx[datasetIdx]\n",
    "            )\n",
    "            datasetIdx = datasetIdx % #trainFiles + 1\n",
    "\n",
    "            if queue:empty() then -- should never enter this\n",
    "                threadLog:write('Q empty again\\n'); threadLog:flush()\n",
    "                os.execute('touch \"' .. outputDir .. 'QEMPTY\"')\n",
    "                while queue:empty() do end\n",
    "            end\n",
    "\n",
    "            local input, target = table.unpack(queue:get())\n",
    "            nJobs = nJobs - 1\n",
    "            threadLog:write('Consume\\n'); threadLog:flush()\n",
    "\n",
    "            batchCPU[k]:copy(input)\n",
    "            batchLabelsCPU[k]:copy(target)\n",
    "        end\n",
    "        threadLog:write('stby batch fill time: ' .. timer:time().real .. '\\n'); threadLog:flush(); timer:reset()\n",
    "        \n",
    "        cutorch.setStream(1)\n",
    "        \n",
    "        batchR:copyAsync(batchCPU)\n",
    "        batchLabelsR:copyAsync(batchLabelsCPU)\n",
    "        \n",
    "        cutorch.setStream(0)\n",
    "        \n",
    "--         print('start fwd')\n",
    "        threadLog:write('batch transfer time: ' .. timer:time().real .. '\\n'); threadLog:flush(); timer:reset()\n",
    "        local outputs = net:forward(batch) -- 2 x 13999 x 19\n",
    "        batchLoss = criterion:forward(outputs:view(-1, nClasses), batchLabels:view(-1))\n",
    "--         print('end fwd')\n",
    "        net:zeroGradParameters()\n",
    "--         print('start bwd')\n",
    "        criterion:backward(outputs:view(-1, nClasses), batchLabels:view(-1))\n",
    "        collectgarbage()\n",
    "        net:backward(batch, criterion.gradInput:view(batchSize,-1,nClasses)) -- accumulate gradients\n",
    "--         print('end bwd')\n",
    "        \n",
    "        threadLog:write('fwd+bwd exec time: ' .. timer:time().real .. '\\n'); threadLog:flush(); timer:reset()\n",
    "    end -- do\n",
    "    \n",
    "    -- detect NaNs\n",
    "    function hasNaN(x) return x:ne(x):sum() > 0 end\n",
    "    if batchLoss ~= batchLoss then -- or hasNaN(net.output) then\n",
    "        print('Loss is NaN')\n",
    "        break\n",
    "    end\n",
    "    \n",
    "    onlineLossLogger:add{batchLoss}\n",
    "    if needToPlot(onlineLossLogger) then onlineLossLogger:plot() end\n",
    "--     print('start optim')\n",
    "    -- optimization step\n",
    "    if separateParams then\n",
    "        for i = 1,#params do\n",
    "            local feval = function(x)\n",
    "                return batchLoss, gradParams[i]\n",
    "            end\n",
    "            optim.adam(feval, params[i], optimStates[i])\n",
    "        end\n",
    "    else\n",
    "        local feval = function(x)\n",
    "            return batchLoss, gradParams\n",
    "        end\n",
    "        optim.adam(feval, params, optimStates)\n",
    "    end\n",
    "    threadLog:write('opt time: ' .. timer:time().real .. '\\n'); threadLog:flush(); timer:reset()\n",
    "    \n",
    "    collectgarbage()\n",
    "    \n",
    "    if (iter-1) % outputFreq == 0 then\n",
    "        net:evaluate()\n",
    "        \n",
    "        local trainLoss, trainIOUclass, trainIOUcategory = \n",
    "            evaluate(net, trainFiles, evaluationIdxTrain,\n",
    "            ((iter-1) % (outputFreq*imgOutputFreq) == 0) and (outputDir .. 'Images/train/'))\n",
    "        \n",
    "        collectgarbage()\n",
    "        \n",
    "        local valLoss, valIOUclass, valIOUcategory = \n",
    "            evaluate(net, valFiles, evaluationIdxVal,\n",
    "            ((iter-1) % (outputFreq*imgOutputFreq) == 0) and (outputDir .. 'Images/val/'))\n",
    "        \n",
    "        collectgarbage()\n",
    "        \n",
    "        lastValScore = valIOUclass\n",
    "        \n",
    "        evalLogger:add{trainLoss, valLoss}\n",
    "        evalLogger:plot()\n",
    "        evalAccLogger:add{trainIOUclass, trainIOUcategory, valIOUclass, valIOUcategory}\n",
    "        evalAccLogger:plot()\n",
    "        \n",
    "        net:training()\n",
    "    end\n",
    "    \n",
    "    if lfs.attributes(outputDir .. 'INTERRUPT') then\n",
    "        os.rename(outputDir .. 'INTERRUPT', outputDir .. 'INTERRUPT_')\n",
    "        break\n",
    "    end\n",
    "end\n",
    "\n",
    "pool:terminate()\n",
    "qMutex:free()\n",
    "threadLog:close()\n",
    "\n",
    "if wDebs then\n",
    "    for k = 1,#wDebs do\n",
    "        wDebs[k]:save(outputDir .. 'wd' .. k .. '.t7')\n",
    "    end\n",
    "end\n",
    "\n",
    "collectgarbage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local optimStatesList = separateParams and optimStates or {optimStates}\n",
    "for k = 1,#optimStatesList do\n",
    "    optimStatesList[k].learningRate = optimStatesList[k].learningRate / 2\n",
    "    optimStatesList[k].t = 0\n",
    "    optimStatesList[k].m:zero()\n",
    "    optimStatesList[k].v:zero()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1e-3 / optimStates.learningRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- do this after INTERRUPTing\n",
    "torch.save(outputDir .. 'net.t7', {copyConvert(#GPUs > 1 and net:get(1) or net, 'torch.FloatTensor'):clearState(), optimStates, GSconfig})\n",
    "\n",
    "torch.save(outputDir .. 'evalLogger.t7', evalLogger.symbols)\n",
    "torch.save(outputDir .. 'evalAccLogger.t7', evalAccLogger.symbols)\n",
    "torch.save(outputDir .. 'onlineLossLogger.t7', onlineLossLogger.symbols)\n",
    "\n",
    "if wDebs then\n",
    "    for k = 1,#wDebs do\n",
    "        wDebs[k]:exportVideo(outputDir .. 'int-layer-' .. k .. '.avi')\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export images for evaluation by `cityscapesScripts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false\t\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.54542613362795\t0.80003757136209\t\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net:evaluate()\n",
    "print(net.train)\n",
    "\n",
    "valLoss, valIOUclass, valIOUcategory = evaluate(net, valFiles, evaluationIdxVal)\n",
    "print(valIOUclass, valIOUcategory)\n",
    "\n",
    "net:training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Total 500\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "50\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "100\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "150\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "200\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "250\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "300\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "350\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "400\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "450\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "500\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net:evaluate()\n",
    "\n",
    "function getResultFilename(s)\n",
    "    local slashIdx = s:find('/')\n",
    "    s = s:sub(slashIdx+1, -1)\n",
    "    local slashIdx = s:find('/')\n",
    "    s = s:sub(slashIdx+1, -1)\n",
    "    local slashIdx = s:find('/')\n",
    "    return s:sub(slashIdx+1, -16) .. 'result.png'\n",
    "end\n",
    "\n",
    "print('Total ' .. #valFiles)\n",
    "\n",
    "os.execute('mkdir \"' .. cityscapes.relative .. 'results\" -p')\n",
    "local input = torch.CudaTensor()\n",
    "\n",
    "for k = 1,#valFiles do\n",
    "    if k % 50 == 0 then print(k) end\n",
    "    \n",
    "    local img, labels = cityscapes.loadSample(valFiles[k])\n",
    "\n",
    "    input:resize(img:size())\n",
    "    input:copy(img)\n",
    "    local outputs = net:forward(nn.utils.addSingletonDimension(input)):squeeze()\n",
    "    local outLabels = \n",
    "        select(2, outputs:float():view(cityscapes.dsize[2], cityscapes.dsize[1], nClasses)\n",
    "            :max(3)):squeeze()\n",
    "    local outLabelsEval = cityscapes.labelsToEval(outLabels)\n",
    "    \n",
    "--     itorch.image(outLabelsEval)\n",
    "    image.savePNG(\n",
    "        cityscapes.relative .. 'results/' .. getResultFilename(valFiles[k].image), \n",
    "        image.scale(outLabelsEval, 2048, 1024, 'simple'))\n",
    "end\n",
    "\n",
    "net:training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
