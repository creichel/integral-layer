{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.setdefaulttensortype('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate reference results using the OLD `IntegralSmartNorm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'image'\n",
    "\n",
    "nInputPlane = 3\n",
    "nWindows = 4\n",
    "h = 200\n",
    "w = 200\n",
    "\n",
    "referencePath = 'Checker/reference.t7'\n",
    "if lfs.attributes(referencePath) then\n",
    "    reference = torch.load(referencePath)\n",
    "else\n",
    "    reference = {}\n",
    "    reference.image = image.scale(image.lena(), h, w)\n",
    "    \n",
    "    reference.xMin = torch.Tensor{-200, 35.5,  99, 0.0}\n",
    "    reference.xMax = torch.Tensor{-195, 35.5, 100, 1.1}\n",
    "    reference.yMin = torch.Tensor{  95, -1.0,  99,  -10}\n",
    "    reference.yMax = torch.Tensor{ 100, -1.0, 100,   0}\n",
    "    \n",
    "    IntegralSmartNorm = nil\n",
    "    debug.getregistry()['IntegralSmartNorm'] = nil \n",
    "    package.loaded['IntegralSmartNorm'] = nil\n",
    "    require 'IntegralSmartNorm'\n",
    "    \n",
    "    int = IntegralSmartNorm(nWindows, h, w)\n",
    "    int.exact = true\n",
    "    int.smart = true\n",
    "    for _, param in ipairs{'xMin', 'xMax', 'yMin', 'yMax'} do\n",
    "        int[param]:copy(reference[param])\n",
    "    end\n",
    "    \n",
    "    int:forward(reference.image)\n",
    "    reference.outputNonNorm = int.outputNonNorm:clone()\n",
    "    reference.outputOnes = torch.repeatTensor(int.outputOnes, nInputPlane, 1, 1)\n",
    "    \n",
    "    torch.manualSeed(666)\n",
    "    reference.gradOutput = torch.rand(int.output:size())\n",
    "    int:backward(reference.image, reference.gradOutput)\n",
    "    for _, param in ipairs{'gradInput', 'gradXMin', 'gradXMax', 'gradYMin', 'gradYMax'} do\n",
    "        reference[param] = int[param]\n",
    "    end\n",
    "    \n",
    "--     torch.save(referencePath, reference)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check new `IntegralSmartNorm`'s output against the reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outputOnes diff:\t0\t\n"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "outputNonNorm diff:\t0\t\n"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "./IntegralSmartNorm.lua:559: attempt to call global 'flattenFirstDims' (a nil value)\nstack traceback:\n\t./IntegralSmartNorm.lua:559: in function 'accGradParameters'\n\t[string \"IntegralSmartNorm = nil...\"]:20: in main chunk\n\t[C]: in function 'xpcall'\n\t...ubb/Programs/Torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ubb/Programs/Torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ubb/Programs/Torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t.../Programs/Torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t.../Programs/Torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t.../Programs/Torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ubb/Programs/Torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00405e40",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "./IntegralSmartNorm.lua:559: attempt to call global 'flattenFirstDims' (a nil value)\nstack traceback:\n\t./IntegralSmartNorm.lua:559: in function 'accGradParameters'\n\t[string \"IntegralSmartNorm = nil...\"]:20: in main chunk\n\t[C]: in function 'xpcall'\n\t...ubb/Programs/Torch/install/share/lua/5.1/itorch/main.lua:210: in function <...ubb/Programs/Torch/install/share/lua/5.1/itorch/main.lua:174>\n\t...ubb/Programs/Torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t.../Programs/Torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t.../Programs/Torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t.../Programs/Torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...ubb/Programs/Torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x00405e40"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gradInput diff:\t3.814697265625e-06\t\n"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IntegralSmartNorm = nil\n",
    "debug.getregistry()['IntegralSmartNorm'] = nil \n",
    "package.loaded['IntegralSmartNorm'] = nil\n",
    "require 'IntegralSmartNorm'\n",
    "\n",
    "int = IntegralSmartNorm(nInputPlane, nWindows, h, w)\n",
    "int.exact = true\n",
    "int.smart = true\n",
    "for _, param in ipairs{'xMin', 'xMax', 'yMin', 'yMax'} do\n",
    "    int[param]:copy(torch.repeatTensor(reference[param], nInputPlane))\n",
    "end\n",
    "\n",
    "int:forward(reference.image)\n",
    "print('outputOnes diff:', (reference.outputOnes - int.outputOnes):abs():mean())\n",
    "print('outputNonNorm diff:', (reference.outputNonNorm - int.outputNonNorm):abs():max())\n",
    "\n",
    "int:updateGradInput(reference.image, reference.gradOutput)\n",
    "print('gradInput diff:', (reference.gradInput - int.gradInput):abs():max())\n",
    "\n",
    "int:accGradParameters(reference.image, reference.gradOutput)\n",
    "for _, param in ipairs{'gradInput', 'gradXMin', 'gradXMax', 'gradYMin', 'gradYMax'} do\n",
    "--     print(param .. ' diff:', \n",
    "--         (reference[param] - int[param]:view(nInputPlane, nWindows):sum(1)):abs():max())\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40000000596046\t\n",
       "0.50999999046326\t\n",
       "0\t\n",
       "0\t\n",
       "input\t\n",
       "(1,.,.) = \n",
       "  5  1\n",
       "  1  1\n",
       "[torch.FloatTensor of size 1x2x2]\n",
       "\n",
       "output\t\n",
       "(1,.,.) = \n",
       "  3.5100  1.1100\n",
       "  1.0000  1.0000\n",
       "[torch.FloatTensor of size 1x2x2]\n",
       "\n",
       "target\t\n",
       "(1,.,.) = \n",
       "  1  1\n",
       "  1  1\n",
       "[torch.FloatTensor of size 1x2x2]\n",
       "\n",
       "loss\t\n",
       "1.5780500173569\t\n",
       "gradOutput\t\n",
       "(1,.,.) = \n",
       "  1.2550  0.0550\n",
       "  0.0000  0.0000\n",
       "[torch.FloatTensor of size 1x2x2]\n",
       "\n",
       "backpropHelper params\t\n",
       "-0.50999999046326\t\n",
       "-0.40000000596046\t\n",
       "-0\t\n",
       "-0\t\n",
       "gradInput\t\n",
       "(1,.,.) = \n",
       "  1.2550  0.0550\n",
       "  0.6400  0.0280\n",
       "[torch.FloatTensor of size 1x2x2]\n",
       "\n"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manualSeed(666)\n",
    "local h,w = 2,2\n",
    "img = torch.ones(1, h, w)\n",
    "\n",
    "int = IntegralSmartNorm(1, 1, h, w)\n",
    "\n",
    "int.exact = true\n",
    "int.smart = false\n",
    "crit = nn.MSECriterion()\n",
    "target = torch.ones(1, h, w)\n",
    "\n",
    "int.xMin[1] = 0.4\n",
    "int.xMax[1] = 0.51\n",
    "int.yMin[1] = 0\n",
    "int.yMax[1] = 0\n",
    "\n",
    "img[{1,1,1}] = 5\n",
    "int:forward(img)\n",
    "print(int.xMin[1])\n",
    "print(int.xMax[1])\n",
    "print(int.yMin[1])\n",
    "print(int.yMax[1])\n",
    "\n",
    "print('input')\n",
    "print(img)\n",
    "print('output')\n",
    "print(int.output)\n",
    "print('target')\n",
    "print(target)\n",
    "loss = crit:forward(int.output, target)\n",
    "print('loss')\n",
    "print(loss)\n",
    "gradOutput = crit:updateGradInput(int.output, target)\n",
    "print('gradOutput')\n",
    "print(gradOutput)\n",
    "int:updateGradInput(img, gradOutput)\n",
    "print('backpropHelper params')\n",
    "print(int.backpropHelper.xMin[1])\n",
    "print(int.backpropHelper.xMax[1])\n",
    "print(int.backpropHelper.yMin[1])\n",
    "print(int.backpropHelper.yMax[1])\n",
    "print('gradInput')\n",
    "print(int.gradInput)\n",
    "\n",
    "params = {}\n",
    "loss = {}\n",
    "deriv = {}\n",
    "derivM = {}\n",
    "\n",
    "local k = 1\n",
    "local step = 0.05\n",
    "local innerStep = 0.005\n",
    "\n",
    "for param = -4,6,step do\n",
    "    params[k] = param\n",
    "    img[{1,1,1}] = param\n",
    "    pred = int:forward(img)\n",
    "    loss[k] = crit:forward(pred, target)\n",
    "    \n",
    "    int:updateGradInput(img, crit:updateGradInput(pred, target))\n",
    "    derivM[k] = int.gradInput[{1,1,1}]\n",
    "    \n",
    "    img[{1,1,1}] = param + innerStep\n",
    "    valFront = crit:forward(int:forward(img), target)\n",
    "    img[{1,1,1}] = param - innerStep\n",
    "    valBack = crit:forward(int:forward(img), target)\n",
    "    \n",
    "    deriv[k] = (valFront - valBack) / (2 * innerStep)\n",
    "    \n",
    "    k = k + 1\n",
    "end\n",
    "\n",
    "-- loss[#loss] = nil\n",
    "-- params[#params] = nil\n",
    "-- derivM[#derivM] = nil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'gnuplot'\n",
    "\n",
    "gnuplot.plot(\n",
    "    {'Loss', torch.Tensor(params), torch.Tensor(loss), '-'},\n",
    "    {'Diff', torch.Tensor(params), torch.Tensor(deriv), '-'},\n",
    "    {'Manual', torch.Tensor(params), torch.Tensor(derivM), '-'}\n",
    ")\n",
    "gnuplot.grid(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
